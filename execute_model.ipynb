{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "\n",
    "from User_based_CF import *\n",
    "from Item_based_CF import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a user-item matrix\n",
    "def create_user_item_matrix(data):\n",
    "    \"\"\"\n",
    "    data: (user, item, rating, timestamp)\n",
    "    \"\"\"\n",
    "    user_list = rating_data[\"User_id\"].values\n",
    "    item_list = rating_data[\"Item_id\"].values\n",
    "    rating_list = rating_data[\"Rating\"].values\n",
    "    user_item_matrix_data = pd.crosstab(index=user_list, columns=item_list, values=rating_list, aggfunc=np.mean,\\\n",
    "        rownames=[\"User_id\"], colnames=[\"Item_id\"])\n",
    "    return user_item_matrix_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify whether the value exists or not.\n",
    "def identify_value_exist(user_item_matrix_data):\n",
    "    \"\"\"\n",
    "    user_item_matrix_data: DataFrame\n",
    "    \"\"\"\n",
    "    return (user_item_matrix_data.isna() == False).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Item_id</th>\n",
       "      <th>Rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>1997-12-04 15:55:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>1998-04-04 19:22:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>1997-11-07 07:18:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>1997-11-27 05:02:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>1998-02-02 05:33:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id  Item_id  Rating           timestamp\n",
       "0      196      242       3 1997-12-04 15:55:49\n",
       "1      186      302       3 1998-04-04 19:22:22\n",
       "2       22      377       1 1997-11-07 07:18:36\n",
       "3      244       51       2 1997-11-27 05:02:03\n",
       "4      166      346       1 1998-02-02 05:33:16"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data to dataframe\n",
    "with open(\"ratings.data\", \"r\") as f:\n",
    "    rating_data = [i.replace(\"\\n\", \"\").split(\"\\t\") for i in f.readlines()]\n",
    "rating_data = pd.DataFrame(np.array(rating_data), columns=[\"User_id\", \"Item_id\", \"Rating\", \"timestamp\"]).astype(\"int\")\n",
    "\n",
    "# transform timestamp into datetime\n",
    "rating_data[\"timestamp\"] = [datetime.utcfromtimestamp(i) for i in rating_data[\"timestamp\"]]\n",
    "rating_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "traindata, testdata = train_test_split(rating_data, test_size=0.25, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform train data into user-item matrix\n",
    "user_item_matrix_data = create_user_item_matrix(traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 889249/889249 [04:55<00:00, 3007.95it/s]\n",
      "100%|██████████| 25000/25000 [13:15<00:00, 31.42it/s]\n",
      "100%|██████████| 25000/25000 [14:03<00:00, 29.63it/s]\n",
      "100%|██████████| 25000/25000 [14:18<00:00, 29.12it/s]\n",
      "100%|██████████| 25000/25000 [14:46<00:00, 28.21it/s]\n",
      "100%|██████████| 25000/25000 [15:16<00:00, 27.27it/s]\n",
      "100%|██████████| 25000/25000 [15:45<00:00, 26.44it/s]\n",
      "100%|██████████| 25000/25000 [16:14<00:00, 25.65it/s]\n",
      "100%|██████████| 25000/25000 [16:52<00:00, 24.69it/s]\n",
      "100%|██████████| 25000/25000 [21:33<00:00, 19.33it/s]\n",
      "100%|██████████| 25000/25000 [26:23<00:00, 15.78it/s]\n",
      "100%|██████████| 25000/25000 [31:19<00:00, 13.30it/s]\n",
      "100%|██████████| 25000/25000 [35:54<00:00, 11.61it/s]\n",
      "100%|██████████| 25000/25000 [42:45<00:00,  9.75it/s]\n",
      "100%|██████████| 25000/25000 [47:17<00:00,  8.81it/s]\n",
      "100%|██████████| 25000/25000 [52:10<00:00,  7.99it/s]\n",
      " 94%|█████████▍| 23455/25000 [54:56<03:35,  7.17it/s]"
     ]
    }
   ],
   "source": [
    "similarity_method = [\"pearson\", \"cosine\"]\n",
    "K_list = [3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "result_dict = dict()\n",
    "\n",
    "for one_similarity_method in similarity_method:\n",
    "    # User-based Collaborative Filtering\n",
    "    user_cf = User_based_CF(traindata, user_item_matrix_data)\n",
    "    user_user_correlation_data = user_cf.compute_correlation(corr_methods=one_similarity_method)\n",
    "\n",
    "    for K in K_list:\n",
    "        # 針對test data做預測以及模型評估（注意，每次計算是針對一筆資料）\n",
    "        pred_user_data = list(map(lambda x: user_cf.predict_without_time(testdata.iloc[x, 0], testdata.iloc[x, 1], num_user=K), tqdm([i for i in range(testdata.shape[0])])))\n",
    "        pred_user_data = [i if i > 0 else 0 for i in pred_user_data]\n",
    "        result_dict[f\"user-based_{one_similarity_method}_{K}\"] = math.sqrt(mean_squared_error(y_true=testdata[\"Rating\"].values, y_pred=np.array(pred_user_data)))\n",
    "\n",
    "    # Item-based Collaborative Filtering\n",
    "    item_cf = Item_based_CF(traindata, user_item_matrix_data)\n",
    "    item_item_correlation_data = item_cf.compute_correlation(corr_methods=one_similarity_method)\n",
    "\n",
    "    for K in K_list:\n",
    "        # 針對test data做預測以及模型評估（注意，每次計算是針對一筆資料）\n",
    "        pred_user_data = list(map(lambda x: user_cf.predict_without_time(testdata.iloc[x, 0], testdata.iloc[x, 1], num_user=K), tqdm([i for i in range(testdata.shape[0])])))\n",
    "        pred_user_data = [i if i > 0 else 0 for i in pred_user_data]\n",
    "        result_dict[f\"item-based_{one_similarity_method}_{K}\"] = math.sqrt(mean_squared_error(y_true=testdata[\"Rating\"].values, y_pred=np.array(pred_user_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2829124/2829124 [05:13<00:00, 9027.61it/s]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix Factorization\n",
    "\n",
    "# 1. 建立模型→使用pytorch class\n",
    "class matrix_factorization(nn.Module):\n",
    "    def __init__(self, num_user_id, num_item_id, num_features):\n",
    "        super(matrix_factorization, self).__init__()\n",
    "        self.num_user_id = num_user_id\n",
    "        self.num_item_id = num_item_id\n",
    "        self.num_features = num_features\n",
    "        self.p_matrix = torch.randn(size=(num_user_id, num_features), requires_grad=True)\n",
    "        self.q_matrix = nn.Linear(num_features, num_item_id)\n",
    "        return\n",
    "\n",
    "    def forward(self):\n",
    "        X = self.q_matrix(self.p_matrix)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 建立Loss function\n",
    "class mf_loss_function_nobias(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(mf_loss_function_nobias, self).__init__()\n",
    "        return\n",
    "\n",
    "    def forward(self, pred_user_item_matrix, true_user_item_matrix):\n",
    "        true_user_item_matrix_value_or_not = (true_user_item_matrix > 0).long()\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 建立Loss function→不使用pytorch class\n",
    "def loss_func(true_user_item_matrix, pred_user_item_matrix, p_matrix, q_matrix, _lambda_=1e-3):\n",
    "    \"\"\"\n",
    "    true_user_item_matrix: 有遺失值的data.frame\n",
    "    pred_user_item_matrix: 由模型計算出來的ndarray\n",
    "    \"\"\"\n",
    "    # 2.1 先辨識出該值是否為有值\n",
    "    identify_true_value_matrix = (true_user_item_matrix > 0).astype(\"int\")\n",
    "\n",
    "    # 2.2 把真實值遺失值的部分補零，並且把它轉成ndarray\n",
    "    true_user_item_matrix = true_user_item_matrix.fillna(0).values\n",
    "\n",
    "    # 2.3 計算y_true-y_pred\n",
    "    true_minus_pred = true_user_item_matrix-pred_user_item_matrix\n",
    "\n",
    "    # 2.4 計算loss\n",
    "    loss = (np.sum( np.power(true_minus_pred, 2) )/2 + _lambda_ * (np.power(p_matrix, 2).sum()+np.power(q_matrix, 2).sum()))/2\n",
    "    return true_minus_pred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 計算gradients\n",
    "def compute_gradients(true_minus_pred, p_matrix, q_matrix, _lambda_=1e-3):\n",
    "    gradient_p_matrix = 2 * np.sum( np.dot(true_minus_pred, q_matrix.T) ) + _lambda_ * math.sqrt(np.power(p_matrix, 2).sum())\n",
    "    gradient_q_matrix = 2 * np.sum( np.dot(true_minus_pred.T, p_matrix)  ) + _lambda_ * math.sqrt(np.power(q_matrix, 2).sum())\n",
    "    return gradient_p_matrix, gradient_q_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Weight Updated\n",
    "def weight_updated(p_matrix, q_matrix, gradient_p_matrix, gradient_q_matrix, learning_rate):\n",
    "    p_matrix += learning_rate * gradient_p_matrix\n",
    "    q_matrix += learning_rate * gradient_q_matrix\n",
    "    return p_matrix, q_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch: 0 ===\n",
      "-155168066.82713935 -154659572.49637195\n",
      "Loss is 9818006.68358793\n",
      "=== Epoch: 1 ===\n",
      "4.705025592135713e+18 4.720503105928497e+18\n",
      "Loss is 9.12292925184716e+20\n",
      "=== Epoch: 2 ===\n",
      "-1.3303509884192438e+50 -1.3259890538305355e+50\n",
      "Loss is 7.824169308536507e+62\n",
      "=== Epoch: 3 ===\n",
      "2.9680675835167162e+144 2.977831251336412e+144\n",
      "Loss is 4.935714554283228e+188\n",
      "=== Epoch: 4 ===\n",
      "-inf -inf\n",
      "Loss is inf\n",
      "=== Epoch: 5 ===\n",
      "inf inf\n",
      "Loss is inf\n",
      "=== Epoch: 6 ===\n",
      "nan nan\n",
      "Loss is nan\n",
      "=== Epoch: 7 ===\n",
      "nan nan\n",
      "Loss is nan\n",
      "=== Epoch: 8 ===\n",
      "nan nan\n",
      "Loss is nan\n",
      "=== Epoch: 9 ===\n",
      "nan nan\n",
      "Loss is nan\n"
     ]
    }
   ],
   "source": [
    "# 5. 建立整體訓練流程\n",
    "num_user_id = 943\n",
    "num_item_id = 1682\n",
    "num_features = 20\n",
    "_lambda_ = 0.1\n",
    "\n",
    "# 1. 建立模型→不使用pytorch class\n",
    "p_matrix = np.random.random(size=(num_user_id, num_features))\n",
    "q_matrix = np.random.random(size=(num_features, num_item_id))\n",
    "epochs = 10\n",
    "learning_rate = 1e-5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"=== Epoch: {epoch} ===\")\n",
    "    pred_user_item_matrix = np.dot(p_matrix, q_matrix)\n",
    "    true_minus_pred, loss = loss_func(true_user_item_matrix=user_item_matrix_data, pred_user_item_matrix=pred_user_item_matrix, p_matrix=p_matrix, q_matrix=q_matrix)\n",
    "    gradient_p_matrix, gradient_q_matrix = compute_gradients(true_minus_pred=true_minus_pred, p_matrix=p_matrix, q_matrix=q_matrix, _lambda_=_lambda_)\n",
    "    p_matrix, q_matrix = weight_updated(p_matrix, q_matrix, gradient_p_matrix, gradient_q_matrix, learning_rate)\n",
    "    print(gradient_p_matrix, gradient_q_matrix)\n",
    "    print(f\"Loss is {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ed225720166559e7176d3793db16a2fd8d295f725007103b21ac3099d2a89ee8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
