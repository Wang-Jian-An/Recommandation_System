{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "\n",
    "from User_based_CF import *\n",
    "from Item_based_CF import *\n",
    "from Matrix_Factorization import *\n",
    "from Factorization_Machine import *\n",
    "from IPNN_model import *\n",
    "from FNN_model import *\n",
    "from OPNN_model import *\n",
    "from PIN_model import *\n",
    "from GMF_NeuCF_model import *\n",
    "from MLP_NeuCF_model import *\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a user-item matrix\n",
    "def create_user_item_matrix(data, user_column_name, item_column_name, result_name):\n",
    "    \"\"\"\n",
    "    data: (user_column_name, item_column_name, result_name, timestamp)\n",
    "    \"\"\"\n",
    "    user_list = data.iloc[:, 0]\n",
    "    item_list = data.iloc[:, 1]\n",
    "    rating_list = data[result_name].values\n",
    "    user_item_matrix_data = pd.crosstab(index=user_list, columns=item_list, values=rating_list, aggfunc=np.mean)\n",
    "    return user_item_matrix_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify whether the value exists or not.\n",
    "def identify_value_exist(user_item_matrix_data):\n",
    "    \"\"\"\n",
    "    user_item_matrix_data: DataFrame\n",
    "    \"\"\"\n",
    "    return (user_item_matrix_data.isna() == False).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a user-item matrix\n",
    "def create_user_item_matrix_for_matrix_factorization(data, unique_user_id, unique_item_id):\n",
    "    \"\"\"\n",
    "    data: (user, item, rating, timestamp)\n",
    "    \"\"\"\n",
    "    user_item_matrix_data = pd.DataFrame(np.array([np.nan] * (len(unique_user_id) * len(unique_item_id))).reshape(len(unique_user_id), len(unique_item_id)),\\\n",
    "        index=unique_user_id, columns=unique_item_id)\n",
    "    \n",
    "    for one_index in data.index:\n",
    "        user_item_matrix_data.loc[data.loc[one_index, \"User_id\"], data.loc[one_index, \"Item_id\"]] = \\\n",
    "            data.loc[one_index, \"Rating\"]\n",
    "    return user_item_matrix_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 要建構四種資料，分別為User的特徵、Item的特徵、User-Item matrix與User對應Item的紀錄\n",
    "def split_four_data(user_data, item_data, user_item_interaction_data, user_column_name, item_column_name, result_name):\n",
    "    \"\"\"\n",
    "    user_data：使用者相關資料（user_id一定要放第一個column）\n",
    "    item_data：物品相關資料（item_id一定要放第二個column）\n",
    "    \"\"\"\n",
    "    all_data = list()\n",
    "    if isinstance(user_data, pd.DataFrame):\n",
    "        # user_feature_data = user_data.iloc[:, 1:]\n",
    "        all_data.append(user_data)\n",
    "    \n",
    "    if isinstance(item_data, pd.DataFrame):\n",
    "        # item_feature_data = item_data.iloc[:, 1:]\n",
    "        all_data.append(item_data)\n",
    "    \n",
    "    if isinstance(user_item_interaction_data, pd.DataFrame):\n",
    "        # transform train data into user-item matrix\n",
    "        user_item_matrix_data = create_user_item_matrix(user_item_interaction_data, user_column_name, item_column_name, result_name)\n",
    "        all_data.append(user_item_interaction_data)\n",
    "        all_data.append(user_item_matrix_data)\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義OneHotEncoding的內容→Movielens\n",
    "def movielens_onehotencoding(merge_data, user_feature_data, movie_feature_data):\n",
    "    user_id_onehotencoding = OneHotEncoder(sparse=False).fit(merge_data[\"user_id\"].values.reshape((-1, 1)))\n",
    "    movie_id_onehotencoding = OneHotEncoder(sparse=False).fit(merge_data[\"movie_id\"].values.reshape((-1, 1)))\n",
    "    user_age_onehotencoding = OneHotEncoder(sparse=False).fit(user_feature_data[\"age\"].values.reshape((-1, 1)))\n",
    "    user_occupation_onehotencoding = OneHotEncoder(sparse=False).fit(user_feature_data[\"occupation\"].values.reshape((-1, 1)))\n",
    "    return user_id_onehotencoding, movie_id_onehotencoding, user_age_onehotencoding, user_occupation_onehotencoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 將每種不同資料前處理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movielens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"data\\Movielens\\movie_genre.dat\", \"r\") as f:\n",
    "    movie_genre = [i.replace(\"\\n\", \"\").split(\"\\t\") for i in f.readlines()]\n",
    "movie_genre = pd.DataFrame(np.array(movie_genre), columns=[\"movie_id\", \"genre\"])\n",
    "movie_genre[\"genre\"] = movie_genre[\"genre\"].astype(\"str\")\n",
    "\n",
    "with open(r\"data\\Movielens\\movie_movie(knn).dat\", \"r\") as f:\n",
    "    movie_movie = [i.replace(\"\\n\", \"\").split(\"\\t\") for i in f.readlines()]\n",
    "movie_movie = pd.DataFrame(np.array(movie_movie), columns=[\"movie1\", \"movie2\", \"similarity\"])\n",
    "\n",
    "with open(r\"data\\Movielens\\user_age.dat\", \"r\") as f:\n",
    "    user_age = [i.replace(\"\\n\", \"\").split(\"\\t\") for i in f.readlines()]\n",
    "user_age = pd.DataFrame(np.array(user_age), columns=[\"user_id\", \"age\"])\n",
    "\n",
    "with open(r\"data\\Movielens\\user_occupation.dat\", \"r\") as f:\n",
    "    user_occupation = [i.replace(\"\\n\", \"\").split(\"\\t\") for i in f.readlines()]\n",
    "user_occupation = pd.DataFrame(np.array(user_occupation), columns=[\"user_id\", \"occupation\"])\n",
    "\n",
    "with open(r\"data\\Movielens\\user_user(knn).dat\", \"r\") as f:\n",
    "    user_user = [i.replace(\"\\n\", \"\").split(\"\\t\") for i in f.readlines()]\n",
    "user_user = pd.DataFrame(np.array(user_user), columns=[\"user1\", \"user2\", \"similarity\"])\n",
    "\n",
    "with open(r\"data\\Movielens\\user_movie.dat\", \"r\") as f:\n",
    "    user_movie = [i.replace(\"\\n\", \"\").split(\"\\t\") for i in f.readlines()]\n",
    "user_movie = pd.DataFrame(np.array(user_movie), columns=[\"user_id\", \"movie_id\", \"rating\", \"timestamp\"])\n",
    "user_movie[\"rating\"] = user_movie[\"rating\"].astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build User-Item matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_matrix_data = create_user_item_matrix(user_movie, user_column_name=\"user_id\", item_column_name=\"item_id\", result_name=\"rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of Rating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 針對電影種類前處理：由於一部電影可能有多種種類，因此將每個種類用OneHotEncoding表示\n",
    "movie_genre[\"index\"] = 1\n",
    "movie_genre = movie_genre.pivot_table(index=\"movie_id\", columns=\"genre\", values=\"index\", fill_value=0)\n",
    "movie_genre = movie_genre.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 5)\n",
      "(100000, 6)\n",
      "(100000, 24)\n"
     ]
    }
   ],
   "source": [
    "rating_merge_data = pd.merge(user_movie, user_age, how=\"inner\", on=\"user_id\")\n",
    "print(rating_merge_data.shape)\n",
    "rating_merge_data = pd.merge(rating_merge_data, user_occupation, how=\"left\", on=\"user_id\")\n",
    "print(rating_merge_data.shape)\n",
    "rating_merge_data = pd.merge(rating_merge_data, movie_genre, how=\"left\", on=\"movie_id\").fillna(0)\n",
    "print(rating_merge_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最終想生成哪些資料\n",
    "# 1. 訓練資料、測試資料\n",
    "# 2. 每個資料的單純User-id、Item-id, User-id所有特徵、Item-id所有特徵、User-Item-interaction、User-Item Matrix\n",
    "    # 把資料分割成訓練資料與測試資料\n",
    "rating_train_merge_data, rating_test_merge_data = train_test_split(rating_merge_data, test_size=0.2, random_state=12345)\n",
    "\n",
    "rating_train_user_id_data, rating_test_user_id_data = rating_train_merge_data[\"user_id\"], rating_test_merge_data[\"user_id\"] # 目標\n",
    "rating_train_movie_id_data, rating_test_movie_id_data = rating_train_merge_data[\"movie_id\"], rating_test_merge_data[\"movie_id\"] # 目標\n",
    "rating_train_user_feature_data, rating_test_user_feature_data = rating_train_merge_data[[\"age\", \"occupation\"]], rating_test_merge_data[[\"age\", \"occupation\"]]\n",
    "rating_train_movie_feature_data, rating_test_movie_feature_data = rating_train_merge_data[movie_genre.columns[1:]], rating_test_merge_data[movie_genre.columns[1:]]\n",
    "rating_train_result_data, rating_test_result_data = rating_train_merge_data[\"rating\"].values, rating_test_merge_data[\"rating\"].values\n",
    "\n",
    "rating_train_user_feature_data, rating_train_movie_feature_data, rating_train_user_item_interaction_data, rating_train_user_item_matrix_data =\\\n",
    "    split_four_data(rating_train_user_feature_data, rating_train_movie_feature_data, rating_train_merge_data[[\"user_id\", \"movie_id\", \"rating\", \"timestamp\"]], user_column_name=\"user_id\", item_column_name=\"movie_id\", result_name=\"rating\")\n",
    "\n",
    "rating_test_user_feature_data, rating_test_movie_feature_data, rating_test_user_item_interaction_data, rating_test_user_item_matrix_data =\\\n",
    "    split_four_data(rating_test_user_feature_data, rating_test_movie_feature_data, rating_test_merge_data[[\"user_id\", \"movie_id\", \"rating\", \"timestamp\"]], user_column_name=\"user_id\", item_column_name=\"movie_id\", result_name=\"rating\")\n",
    "\n",
    "del rating_test_user_item_matrix_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 定義OneHotEncoding的內容→Movielens\n",
    "rating_user_id_onehotencoding, rating_movie_id_onehotencoding, rating_user_age_onehotencoding, rating_user_occupation_onehotencoding =\\\n",
    "    movielens_onehotencoding(rating_merge_data, rating_train_user_feature_data, rating_train_movie_feature_data)\n",
    "\n",
    "# 2. 把所有訓練資料以及測試資料都轉成OneHotEncoding\n",
    "rating_train_user_age_onehotencoding, rating_test_user_age_onehotencoding =\\\n",
    "    list(map(lambda x: rating_user_age_onehotencoding.transform(x), [rating_train_user_feature_data[\"age\"].values.reshape((-1, 1)), rating_test_user_feature_data[\"age\"].values.reshape((-1, 1))]))\n",
    "rating_train_user_occupation_onehotencoding, rating_test_user_occupation_onehotencoding =\\\n",
    "    list(map(lambda x: rating_user_occupation_onehotencoding.transform(x), [rating_train_user_feature_data[\"occupation\"].values.reshape((-1, 1)), rating_test_user_feature_data[\"occupation\"].values.reshape((-1, 1))]))\n",
    "rating_train_user_id_onehotencoding, rating_test_user_id_onehotencoding =\\\n",
    "    list(map(lambda x: rating_user_id_onehotencoding.transform(x), [rating_train_user_id_data.values.reshape((-1, 1)), rating_test_user_id_data.values.reshape((-1, 1))]))\n",
    "rating_train_movie_id_onehotencoding, rating_test_movie_id_onehotencoding =\\\n",
    "    list(map(lambda x: rating_movie_id_onehotencoding.transform(x), [rating_train_movie_id_data.values.reshape((-1, 1)), rating_test_movie_id_data.values.reshape((-1, 1))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del rating_merge_data, rating_train_merge_data, rating_test_merge_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "綜合上述前處理過程，只需要保留以下幾個變數：\n",
    "1. rating_train_user_id_onehoteocoding, rating_test_user_id_onehotencoding\n",
    "2. rating_train_movie_id_onehotencoding, rating_test_movie_id_onehotencoding\n",
    "3. rating_train_user_age_onehotencoding, rating_test_user_age_onehotencoding\n",
    "4. rating_train_user_occupation_onehotencoding, rating_test_user_occupation_onehotencoding\n",
    "5. rating_train_movie_feature_data, rating_test_movie_feature_data\n",
    "6. rating_train_user_item_interaction_data, rating_test_user_item_interaction_data: pd.DataFrame\n",
    "7. rating_train_user_item_matrix_data: pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of binary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 產生binary data→定義某個user是否會對某個item做評論\n",
    "# 1. 產生某個值是否為真實值\n",
    "identify_value_exist_binary = (user_item_matrix_data.isna() == False).astype(\"int\")\n",
    "\n",
    "# 2. 產生index名稱為column\n",
    "identify_value_exist_binary[\"user_id\"] = identify_value_exist_binary.index\n",
    "\n",
    "# 3. pandas melt\n",
    "binary_result = pd.melt(identify_value_exist_binary, id_vars=[\"user_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1586126, 4)\n",
      "(1586126, 5)\n",
      "(1586126, 23)\n"
     ]
    }
   ],
   "source": [
    "binary_merge_data = pd.merge(binary_result, user_age, how=\"inner\", on=\"user_id\")\n",
    "print(binary_merge_data.shape)\n",
    "binary_merge_data = pd.merge(binary_merge_data, user_occupation, how=\"left\", on=\"user_id\")\n",
    "print(binary_merge_data.shape)\n",
    "binary_merge_data = pd.merge(binary_merge_data, movie_genre, how=\"left\", on=\"movie_id\").fillna(0)\n",
    "print(binary_merge_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最終想生成哪些資料\n",
    "# 1. 訓練資料、測試資料\n",
    "# 2. 每個資料的單純User-id、Item-id, User-id所有特徵、Item-id所有特徵、User-Item-interaction、User-Item Matrix\n",
    "    # 把資料分割成訓練資料與測試資料\n",
    "binary_train_merge_data, binary_test_merge_data = train_test_split(binary_merge_data, test_size=0.2, random_state=12345)\n",
    "\n",
    "binary_train_user_id_data, binary_test_user_id_data = binary_train_merge_data[\"user_id\"], binary_test_merge_data[\"user_id\"] # 目標\n",
    "binary_train_movie_id_data, binary_test_movie_id_data = binary_train_merge_data[\"movie_id\"], binary_test_merge_data[\"movie_id\"] # 目標\n",
    "binary_train_user_feature_data, binary_test_user_feature_data = binary_train_merge_data[[\"age\", \"occupation\"]], binary_test_merge_data[[\"age\", \"occupation\"]]\n",
    "binary_train_movie_feature_data, binary_test_movie_feature_data = binary_train_merge_data[movie_genre.columns[1:]], binary_test_merge_data[movie_genre.columns[1:]]\n",
    "binary_train_result_data, binary_test_result_data = binary_train_merge_data[\"value\"].values, binary_test_merge_data[\"value\"].values\n",
    "\n",
    "binary_train_user_feature_data, binary_train_movie_feature_data, binary_train_user_item_interaction_data, binary_train_user_item_matrix_data =\\\n",
    "    split_four_data(binary_train_user_feature_data, binary_train_movie_feature_data, binary_train_merge_data[[\"user_id\", \"movie_id\", \"value\"]], user_column_name=\"user_id\", item_column_name=\"movie_id\", result_name=\"value\")\n",
    "\n",
    "binary_test_user_feature_data, binary_test_movie_feature_data, binary_test_user_item_interaction_data, binary_test_user_item_matrix_data =\\\n",
    "    split_four_data(binary_test_user_feature_data, binary_test_movie_feature_data, binary_test_merge_data[[\"user_id\", \"movie_id\", \"value\"]], user_column_name=\"user_id\", item_column_name=\"movie_id\", result_name=\"value\")\n",
    "\n",
    "del binary_train_user_item_matrix_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 定義OneHotEncoding的內容→Movielens\n",
    "binary_user_id_onehotencoding, binary_movie_id_onehotencoding, binary_user_age_onehotencoding, binary_user_occupation_onehotencoding =\\\n",
    "    movielens_onehotencoding(binary_merge_data, binary_train_user_feature_data, binary_train_movie_feature_data)\n",
    "\n",
    "# 2. 把所有訓練資料以及測試資料都轉成OneHotEncoding\n",
    "binary_train_user_age_onehotencoding, binary_test_user_age_onehotencoding =\\\n",
    "    list(map(lambda x: binary_user_age_onehotencoding.transform(x), [binary_train_user_feature_data[\"age\"].values.reshape((-1, 1)), binary_test_user_feature_data[\"age\"].values.reshape((-1, 1))]))\n",
    "binary_train_user_occupation_onehotencoding, binary_test_user_occupation_onehotencoding =\\\n",
    "    list(map(lambda x: binary_user_occupation_onehotencoding.transform(x), [binary_train_user_feature_data[\"occupation\"].values.reshape((-1, 1)), binary_test_user_feature_data[\"occupation\"].values.reshape((-1, 1))]))\n",
    "binary_train_user_id_onehotencoding, binary_test_user_id_onehotencoding =\\\n",
    "    list(map(lambda x: binary_user_id_onehotencoding.transform(x), [binary_train_user_id_data.values.reshape((-1, 1)), binary_test_user_id_data.values.reshape((-1, 1))]))\n",
    "binary_train_movie_id_onehotencoding, binary_test_movie_id_onehotencoding =\\\n",
    "    list(map(lambda x: binary_movie_id_onehotencoding.transform(x), [binary_train_movie_id_data.values.reshape((-1, 1)), binary_test_movie_id_data.values.reshape((-1, 1))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1268900, 8), (1268900, 18))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_train_user_age_onehotencoding.shape, binary_train_movie_feature_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Douban_Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 889249/889249 [05:53<00:00, 2516.07it/s]\n",
      "  5%|▍         | 934/20000 [01:19<26:59, 11.77it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\JIAN_A~1\\AppData\\Local\\Temp/ipykernel_10536/1634166879.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mK\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mK_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m# 針對test data做預測以及模型評估（注意，每次計算是針對一筆資料）\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mpred_user_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0muser_cf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_without_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrating_test_user_item_interaction_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrating_test_user_item_interaction_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_column_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"user_id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_column_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"movie_id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_user\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrating_test_user_item_interaction_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mpred_user_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpred_user_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mCF_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf\"user-based_{one_similarity_method}_{K}\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrating_test_user_item_interaction_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"rating\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_user_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\JIAN_A~1\\AppData\\Local\\Temp/ipykernel_10536/1634166879.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mK\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mK_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m# 針對test data做預測以及模型評估（注意，每次計算是針對一筆資料）\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mpred_user_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0muser_cf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_without_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrating_test_user_item_interaction_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrating_test_user_item_interaction_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_column_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"user_id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_column_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"movie_id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_user\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrating_test_user_item_interaction_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mpred_user_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpred_user_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mCF_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf\"user-based_{one_similarity_method}_{K}\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrating_test_user_item_interaction_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"rating\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_user_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Recommandation_System\\User_based_CF.py\u001b[0m in \u001b[0;36mpredict_without_time\u001b[1;34m(self, user_id, item_id, user_column_name, item_column_name, num_user)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;31m# 2. 找到某個相似的人中針對某個item的rating與時間\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mpredict_user\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraindata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimilar_user\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraindata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser_column_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraindata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem_column_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mitem_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;31m# 3. 計算分母與分子\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python3.7.5\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3447\u001b[0m         \u001b[1;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3448\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3449\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3451\u001b[0m         \u001b[1;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python3.7.5\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3500\u001b[0m         \u001b[1;31m# check_bool_indexer will throw exception if Series key cannot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3501\u001b[0m         \u001b[1;31m# be reindexed to match DataFrame rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3502\u001b[1;33m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3503\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3504\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python3.7.5\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36mcheck_bool_indexer\u001b[1;34m(index, key)\u001b[0m\n\u001b[0;32m   2398\u001b[0m         \u001b[1;31m# GH 33924\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2399\u001b[0m         \u001b[1;31m# key may contain nan elements, check_array_indexer needs bool array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2400\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2401\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcheck_array_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python3.7.5\\lib\\site-packages\\pandas\\core\\construction.py\u001b[0m in \u001b[0;36marray\u001b[1;34m(data, dtype, copy)\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mTimedeltaArray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_from_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 366\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mPandasArray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_from_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python3.7.5\\lib\\site-packages\\pandas\\core\\arrays\\numpy_.py\u001b[0m in \u001b[0;36m_from_sequence\u001b[1;34m(cls, scalars, dtype, copy)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;31m# Union[Tuple[Any, int], Tuple[Any, Union[int, Sequence[int]]], List[Any],\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;31m# _DTypeDict, Tuple[Any, Any]]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscalars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         if (\n\u001b[0;32m    102\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "similarity_method = [\"pearson\", \"cosine\"]\n",
    "K_list = [3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "CF_result = dict()\n",
    "\n",
    "for one_similarity_method in similarity_method:\n",
    "    # User-based Collaborative Filtering\n",
    "    user_cf = User_based_CF(rating_train_user_item_interaction_data, user_item_matrix_data)\n",
    "    user_user_correlation_data = user_cf.compute_correlation(corr_methods=one_similarity_method)\n",
    "\n",
    "    for K in K_list:\n",
    "        # 針對test data做預測以及模型評估（注意，每次計算是針對一筆資料）\n",
    "        pred_user_data = list(map(lambda x: user_cf.predict_without_time(rating_test_user_item_interaction_data.iloc[x, 0], rating_test_user_item_interaction_data.iloc[x, 1], user_column_name=\"user_id\", item_column_name=\"movie_id\", num_user=K), tqdm([i for i in range(rating_test_user_item_interaction_data.shape[0])])))\n",
    "        pred_user_data = [i if i > 0 else 0 for i in pred_user_data]\n",
    "        CF_result[f\"user-based_{one_similarity_method}_{K}\"] = math.sqrt(mean_squared_error(y_true=rating_test_user_item_interaction_data[\"rating\"].values, y_pred=np.array(pred_user_data)))\n",
    "        break\n",
    "\n",
    "    # Item-based Collaborative Filtering\n",
    "    item_cf = Item_based_CF(rating_train_user_item_interaction_data, user_item_matrix_data)\n",
    "    item_item_correlation_data = item_cf.compute_correlation(corr_methods=one_similarity_method)\n",
    "\n",
    "    for K in K_list:\n",
    "        # 針對test data做預測以及模型評估（注意，每次計算是針對一筆資料）\n",
    "        pred_user_data = list(map(lambda x: item_cf.predict_without_time(rating_test_user_item_interaction_data.iloc[x, 0], rating_test_user_item_interaction_data.iloc[x, 1], user_column_name=\"user_id\", item_column_name=\"movie_id\", num_item=K), tqdm([i for i in range(rating_test_user_item_interaction_data.shape[0])])))\n",
    "        pred_user_data = [i if i > 0 else 0 for i in pred_user_data]\n",
    "        CF_result[f\"item-based_{one_similarity_method}_{K}\"] = math.sqrt(mean_squared_error(y_true=rating_test_user_item_interaction_data[\"rating\"].values, y_pred=np.array(pred_user_data)))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch: 0 Train Loss: 20.599211405299222\n",
      "=== Epoch: 1 Train Loss: 20.59466254555195\n",
      "=== Epoch: 2 Train Loss: 20.590115948601476\n",
      "=== Epoch: 3 Train Loss: 20.585571626313254\n",
      "=== Epoch: 4 Train Loss: 20.581029547581313\n",
      "=== Epoch: 5 Train Loss: 20.57648974614625\n",
      "=== Epoch: 6 Train Loss: 20.57195217663575\n",
      "=== Epoch: 7 Train Loss: 20.567416873053997\n",
      "=== Epoch: 8 Train Loss: 20.56288380328726\n",
      "=== Epoch: 9 Train Loss: 20.55835299136292\n",
      "=== Epoch: 10 Train Loss: 20.553824444222204\n",
      "=== Epoch: 11 Train Loss: 20.549298140749443\n",
      "=== Epoch: 12 Train Loss: 20.544774087423903\n",
      "=== Epoch: 13 Train Loss: 20.54025230256187\n",
      "=== Epoch: 14 Train Loss: 20.535732735034546\n",
      "=== Epoch: 15 Train Loss: 20.531215408604808\n",
      "=== Epoch: 16 Train Loss: 20.526700349304868\n",
      "=== Epoch: 17 Train Loss: 20.522187512591717\n",
      "=== Epoch: 18 Train Loss: 20.51767692373556\n",
      "=== Epoch: 19 Train Loss: 20.513168575551603\n",
      "=== Epoch: 20 Train Loss: 20.50866248156334\n",
      "=== Epoch: 21 Train Loss: 20.50415860576128\n",
      "=== Epoch: 22 Train Loss: 20.4996569612431\n",
      "=== Epoch: 23 Train Loss: 20.495157562353914\n",
      "=== Epoch: 24 Train Loss: 20.49066039021396\n",
      "=== Epoch: 25 Train Loss: 20.486165466206646\n",
      "=== Epoch: 26 Train Loss: 20.48167279065365\n",
      "=== Epoch: 27 Train Loss: 20.477182322945104\n",
      "=== Epoch: 28 Train Loss: 20.472694078446747\n",
      "=== Epoch: 29 Train Loss: 20.468208070293315\n",
      "=== Epoch: 30 Train Loss: 20.463724284641156\n",
      "=== Epoch: 31 Train Loss: 20.459242725947608\n",
      "=== Epoch: 32 Train Loss: 20.45476338660196\n",
      "=== Epoch: 33 Train Loss: 20.450286285978027\n",
      "=== Epoch: 34 Train Loss: 20.44581139180416\n",
      "=== Epoch: 35 Train Loss: 20.441338699093993\n",
      "=== Epoch: 36 Train Loss: 20.43686825580392\n",
      "=== Epoch: 37 Train Loss: 20.432400035400256\n",
      "=== Epoch: 38 Train Loss: 20.427934005322353\n",
      "=== Epoch: 39 Train Loss: 20.42347021203003\n",
      "=== Epoch: 40 Train Loss: 20.419008631589737\n",
      "=== Epoch: 41 Train Loss: 20.4145492521406\n",
      "=== Epoch: 42 Train Loss: 20.41009209023775\n",
      "=== Epoch: 43 Train Loss: 20.40563713246664\n",
      "=== Epoch: 44 Train Loss: 20.401184405557274\n",
      "=== Epoch: 45 Train Loss: 20.396733879410558\n",
      "=== Epoch: 46 Train Loss: 20.392285536676933\n",
      "=== Epoch: 47 Train Loss: 20.387839399240793\n",
      "=== Epoch: 48 Train Loss: 20.38339550024515\n",
      "=== Epoch: 49 Train Loss: 20.378953813715643\n",
      "=== Epoch: 50 Train Loss: 20.374514300018543\n",
      "=== Epoch: 51 Train Loss: 20.370076973033676\n",
      "=== Epoch: 52 Train Loss: 20.36564186045224\n",
      "=== Epoch: 53 Train Loss: 20.361208964234347\n",
      "=== Epoch: 54 Train Loss: 20.356778253037742\n",
      "=== Epoch: 55 Train Loss: 20.35234974528683\n",
      "=== Epoch: 56 Train Loss: 20.347923438736363\n",
      "=== Epoch: 57 Train Loss: 20.343499322544393\n",
      "=== Epoch: 58 Train Loss: 20.339077382183234\n",
      "=== Epoch: 59 Train Loss: 20.334657632960973\n",
      "=== Epoch: 60 Train Loss: 20.330240091173053\n",
      "=== Epoch: 61 Train Loss: 20.32582475381487\n",
      "=== Epoch: 62 Train Loss: 20.321411597993887\n",
      "=== Epoch: 63 Train Loss: 20.317000590602667\n",
      "=== Epoch: 64 Train Loss: 20.312591779568045\n",
      "=== Epoch: 65 Train Loss: 20.30818519733578\n",
      "=== Epoch: 66 Train Loss: 20.30378077937936\n",
      "=== Epoch: 67 Train Loss: 20.299378530816895\n",
      "=== Epoch: 68 Train Loss: 20.2949784737708\n",
      "=== Epoch: 69 Train Loss: 20.290580585169256\n",
      "=== Epoch: 70 Train Loss: 20.286184895397398\n",
      "=== Epoch: 71 Train Loss: 20.28179137695623\n",
      "=== Epoch: 72 Train Loss: 20.27740002977915\n",
      "=== Epoch: 73 Train Loss: 20.27301086719819\n",
      "=== Epoch: 74 Train Loss: 20.268623857940312\n",
      "=== Epoch: 75 Train Loss: 20.26423902514937\n",
      "=== Epoch: 76 Train Loss: 20.259856394159527\n",
      "=== Epoch: 77 Train Loss: 20.255475927698587\n",
      "=== Epoch: 78 Train Loss: 20.25109761722525\n",
      "=== Epoch: 79 Train Loss: 20.24672145334596\n",
      "=== Epoch: 80 Train Loss: 20.242347476875523\n",
      "=== Epoch: 81 Train Loss: 20.237975660390145\n",
      "=== Epoch: 82 Train Loss: 20.233606028708937\n",
      "=== Epoch: 83 Train Loss: 20.22923855172923\n",
      "=== Epoch: 84 Train Loss: 20.22487324903178\n",
      "=== Epoch: 85 Train Loss: 20.22051007300192\n",
      "=== Epoch: 86 Train Loss: 20.216149085621414\n",
      "=== Epoch: 87 Train Loss: 20.211790245314212\n",
      "=== Epoch: 88 Train Loss: 20.207433560316396\n",
      "=== Epoch: 89 Train Loss: 20.20307904371354\n",
      "=== Epoch: 90 Train Loss: 20.19872668141008\n",
      "=== Epoch: 91 Train Loss: 20.194376467451576\n",
      "=== Epoch: 92 Train Loss: 20.190028406257046\n",
      "=== Epoch: 93 Train Loss: 20.185682505095283\n",
      "=== Epoch: 94 Train Loss: 20.18133873847724\n",
      "=== Epoch: 95 Train Loss: 20.17699714914151\n",
      "=== Epoch: 96 Train Loss: 20.17265769389493\n",
      "=== Epoch: 97 Train Loss: 20.16832039316556\n",
      "=== Epoch: 98 Train Loss: 20.163985233349702\n",
      "=== Epoch: 99 Train Loss: 20.159652229270964\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "learning_rate = 1e-2\n",
    "num_user_id = user_item_matrix_data.shape[0]\n",
    "num_item_id = user_item_matrix_data.shape[1]\n",
    "num_features = 10\n",
    "\n",
    "model = matrix_factorization(true_user_item_matrix=rating_train_user_item_matrix_data, num_features=num_features)\n",
    "model.fit(epochs=epochs, learning_rate=learning_rate, regularization_rate=1e-2, bias_or_not=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71751</th>\n",
       "      <td>655</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>891585279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80493</th>\n",
       "      <td>748</td>\n",
       "      <td>208</td>\n",
       "      <td>4</td>\n",
       "      <td>879454522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2655</th>\n",
       "      <td>303</td>\n",
       "      <td>388</td>\n",
       "      <td>2</td>\n",
       "      <td>879544365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53233</th>\n",
       "      <td>463</td>\n",
       "      <td>111</td>\n",
       "      <td>2</td>\n",
       "      <td>877385414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91141</th>\n",
       "      <td>864</td>\n",
       "      <td>588</td>\n",
       "      <td>3</td>\n",
       "      <td>888887289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29759</th>\n",
       "      <td>274</td>\n",
       "      <td>71</td>\n",
       "      <td>4</td>\n",
       "      <td>878946612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88142</th>\n",
       "      <td>833</td>\n",
       "      <td>234</td>\n",
       "      <td>3</td>\n",
       "      <td>875122884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36759</th>\n",
       "      <td>338</td>\n",
       "      <td>168</td>\n",
       "      <td>3</td>\n",
       "      <td>879438225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90574</th>\n",
       "      <td>845</td>\n",
       "      <td>286</td>\n",
       "      <td>5</td>\n",
       "      <td>885409719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54452</th>\n",
       "      <td>486</td>\n",
       "      <td>220</td>\n",
       "      <td>3</td>\n",
       "      <td>879875441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id movie_id  rating  timestamp\n",
       "71751     655       52       3  891585279\n",
       "80493     748      208       4  879454522\n",
       "2655      303      388       2  879544365\n",
       "53233     463      111       2  877385414\n",
       "91141     864      588       3  888887289\n",
       "...       ...      ...     ...        ...\n",
       "29759     274       71       4  878946612\n",
       "88142     833      234       3  875122884\n",
       "36759     338      168       3  879438225\n",
       "90574     845      286       5  885409719\n",
       "54452     486      220       3  879875441\n",
       "\n",
       "[20000 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_test_user_item_interaction_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 91/20000 [00:00<00:45, 437.18it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'1581'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\python3.7.5\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python3.7.5\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\python3.7.5\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '1581'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\JIAN_A~1\\AppData\\Local\\Temp/ipykernel_10536/3269911532.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrating_test_user_item_interaction_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Recommandation_System\\Matrix_Factorization.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, testdata)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mtestdata\u001b[0m\u001b[0;31m：\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;31m，\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0muser_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrating\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \"\"\"\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[0mtestdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"yhat\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0muser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"MSE: {mean_squared_error(y_true=testdata.iloc[:, 2], y_pred=testdata['yhat'])}\\nr2_score: {r2_score(y_true=testdata.iloc[:, 2], y_pred=testdata['yhat'])}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Recommandation_System\\Matrix_Factorization.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(user, item)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mtestdata\u001b[0m\u001b[0;31m：\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;31m，\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0muser_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrating\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \"\"\"\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[0mtestdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"yhat\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0muser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"MSE: {mean_squared_error(y_true=testdata.iloc[:, 2], y_pred=testdata['yhat'])}\\nr2_score: {r2_score(y_true=testdata.iloc[:, 2], y_pred=testdata['yhat'])}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Recommandation_System\\Matrix_Factorization.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, user_id, item_id)\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mq_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0myhat_dataframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_id_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_id_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0myhat_dataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python3.7.5\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    923\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 925\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    926\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    927\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python3.7.5\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIndexingError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m         \u001b[1;31m# no multi-index, so validate all of the indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python3.7.5\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    860\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0msection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m                 \u001b[1;31m# This is an elided recursive call to iloc/loc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"not applicable\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python3.7.5\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    929\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 931\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python3.7.5\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1162\u001b[0m         \u001b[1;31m# fall thru to straight lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1164\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python3.7.5\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1111\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[1;31m# GH#5667 this will fail if the label is not present in the axis.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1113\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python3.7.5\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mxs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   3774\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Expected label or tuple of labels, got {key}\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3775\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3776\u001b[1;33m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3778\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python3.7.5\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '1581'"
     ]
    }
   ],
   "source": [
    "model.evaluate(testdata=rating_test_user_item_interaction_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factorization Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_item_interaction的結構：<user_id, item_id, result, timestamp>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_features = 10\n",
    "\n",
    "# 1. 把所有東西包成dataloader\n",
    "train_dataset = TensorDataset( torch.FloatTensor(rating_train_user_age_onehotencoding),\n",
    "                               torch.FloatTensor(rating_train_user_occupation_onehotencoding),\n",
    "                               torch.FloatTensor(rating_train_movie_feature_data.values),\n",
    "                               torch.FloatTensor(rating_train_result_data) )\n",
    "test_dataset = TensorDataset(  torch.FloatTensor(rating_test_user_age_onehotencoding),\n",
    "                               torch.FloatTensor(rating_test_user_occupation_onehotencoding),\n",
    "                               torch.FloatTensor(rating_test_movie_feature_data.values),\n",
    "                               torch.FloatTensor(rating_test_result_data))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128)\n",
    "\n",
    "\n",
    "# 2. 呼叫模型與設定Loss function\n",
    "model = fm_model(num_user_age=binary_train_user_age_onehotencoding.shape[1], \n",
    "                 num_user_occupation=binary_train_user_occupation_onehotencoding.shape[1], \n",
    "                 num_movie_genre=binary_train_movie_feature_data.values.shape[1],\n",
    "                 num_features=num_features,\n",
    "                 methods = \"regression\")\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch: 0, Train Loss: 2831.227592587471\n",
      "=== Epoch: 1, Train Loss: 811.0931701660156\n",
      "=== Epoch: 2, Train Loss: 805.9960036277771\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "train_each_iteration_loss = list()\n",
    "train_loss_list = list()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    for torch_user_age, torch_user_occupation, torch_movie_genre, torch_result in train_dataloader:\n",
    "        yhat = model(user_age_feature=torch_user_age, \n",
    "                     user_occupation_feature=torch_user_occupation,\n",
    "                     movie_genre_feature=torch_movie_genre)\n",
    "\n",
    "        loss = loss_func(yhat, torch_result)\n",
    "        train_loss += loss.item()\n",
    "        train_each_iteration_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    train_loss_list.append(train_loss)\n",
    "    print(f\"=== Epoch: {epoch}, Train Loss: {train_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_features = 10\n",
    "\n",
    "# 1. 把所有東西包成dataloader\n",
    "train_dataset = TensorDataset( torch.FloatTensor(binary_train_user_age_onehotencoding),\n",
    "                               torch.FloatTensor(binary_train_user_occupation_onehotencoding),\n",
    "                               torch.FloatTensor(binary_train_movie_feature_data.values),\n",
    "                               torch.FloatTensor(binary_train_result_data) )\n",
    "test_dataset = TensorDataset(  torch.FloatTensor(binary_test_user_age_onehotencoding),\n",
    "                               torch.FloatTensor(binary_test_user_occupation_onehotencoding),\n",
    "                               torch.FloatTensor(binary_test_movie_feature_data.values),\n",
    "                               torch.FloatTensor(binary_test_result_data))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128)\n",
    "\n",
    "\n",
    "# 2. 呼叫模型與設定Loss function\n",
    "model = fm_model(num_user_age=binary_train_user_age_onehotencoding.shape[1], \n",
    "                 num_user_occupation=binary_train_user_occupation_onehotencoding.shape[1], \n",
    "                 num_movie_genre=binary_train_movie_feature_data.values.shape[1],\n",
    "                 num_features=num_features,\n",
    "                 methods = \"classification\")\n",
    "loss_func = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch: 0, Train Loss: 2336.783412784338\n",
      "=== Epoch: 1, Train Loss: 2331.496040932834\n",
      "=== Epoch: 2, Train Loss: 2326.598101451993\n",
      "=== Epoch: 3, Train Loss: 2321.9458227828145\n",
      "=== Epoch: 4, Train Loss: 2317.4644750207663\n",
      "=== Epoch: 5, Train Loss: 2313.1144154295325\n",
      "=== Epoch: 6, Train Loss: 2308.8806760013103\n",
      "=== Epoch: 7, Train Loss: 2304.766260832548\n",
      "=== Epoch: 8, Train Loss: 2300.786325581372\n",
      "=== Epoch: 9, Train Loss: 2296.961825057864\n",
      "=== Epoch: 10, Train Loss: 2293.3146854266524\n",
      "=== Epoch: 11, Train Loss: 2289.863220587373\n",
      "=== Epoch: 12, Train Loss: 2286.6195099279284\n",
      "=== Epoch: 13, Train Loss: 2283.588393494487\n",
      "=== Epoch: 14, Train Loss: 2280.768659673631\n",
      "=== Epoch: 15, Train Loss: 2278.153487429023\n",
      "=== Epoch: 16, Train Loss: 2275.7329700142145\n",
      "=== Epoch: 17, Train Loss: 2273.495465449989\n",
      "=== Epoch: 18, Train Loss: 2271.428537324071\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-8c6e622d9017>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mtorch_user_age\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch_user_occupation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch_movie_genre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch_result\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         yhat = model(user_age_feature=torch_user_age, \n\u001b[0;32m     11\u001b[0m                      \u001b[0muser_occupation_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch_user_occupation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python 3.7.5\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python 3.7.5\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python 3.7.5\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\python 3.7.5\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python 3.7.5\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python 3.7.5\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'numpy'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'string_'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model Training\n",
    "epochs = 30\n",
    "\n",
    "train_each_iteration_loss = list()\n",
    "train_loss_list = list()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    for torch_user_age, torch_user_occupation, torch_movie_genre, torch_result in train_dataloader:\n",
    "        yhat = model(user_age_feature=torch_user_age, \n",
    "                     user_occupation_feature=torch_user_occupation,\n",
    "                     movie_genre_feature=torch_movie_genre)\n",
    "\n",
    "        loss = loss_func(yhat, torch_result.reshape((-1, 1)))\n",
    "        train_loss += loss.item()\n",
    "        train_each_iteration_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    train_loss_list.append(train_loss)\n",
    "    print(f\"=== Epoch: {epoch}, Train Loss: {train_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "all_yhat = list()\n",
    "test_loss = 0.0\n",
    "\n",
    "for torch_user_age, torch_user_occupation, torch_movie_genre, torch_result in test_dataloader:\n",
    "    yhat = model(user_age_feature=torch_user_age, \n",
    "                    user_occupation_feature=torch_user_occupation,\n",
    "                    movie_genre_feature=torch_movie_genre)\n",
    "\n",
    "    loss = loss_func(yhat, torch_result.reshape((-1, 1)))\n",
    "    test_loss += loss.item()\n",
    "    all_yhat.extend(yhat[:, 0].detach().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_topk_recall(testdata,\n",
    "                         one_user,\n",
    "                         user_column, \n",
    "                         item_column, \n",
    "                         true_result_column, \n",
    "                         topk=10):\n",
    "    \"\"\"\n",
    "    testdata: data.frame，同時有user_id, item_id, rating, yhat\n",
    "    \"\"\"\n",
    "    one_user_data = binary_test_user_item_interaction_data[binary_test_user_item_interaction_data[user_column] == one_user]\n",
    "\n",
    "    # 2. 針對某個User，挑出所有真實有評分的Item，以及挑出預測前十名的Item\n",
    "    true_item = list(one_user_data[one_user_data[true_result_column] == 1][item_column])\n",
    "    predict_item = list(one_user_data.sort_values(\"yhat\", ascending=True)[item_column][:10])\n",
    "\n",
    "    # 3. 計算所有有真實評分的Item的數量\n",
    "    length_true_item = len(true_item)\n",
    "\n",
    "    # 4. 計算預測與真實有相對應的資料\n",
    "    length_true_predict_match = sum([1 if i in predict_item else 0 for i in true_item])\n",
    "\n",
    "    # 5. 計算Recall\n",
    "    try:\n",
    "        topk_recall = length_true_predict_match / length_true_item\n",
    "    except:\n",
    "        topk_recall = 0\n",
    "    return topk_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "# Recall@10\n",
    "\n",
    "# 0. 把預測結果鑲嵌至testdata\n",
    "binary_test_user_item_interaction_data[\"yhat\"] = np.array(all_yhat)\n",
    "\n",
    "# 1. 建立User清單\n",
    "binary_test_user_id = list(binary_test_user_item_interaction_data[\"user_id\"].unique())\n",
    "\n",
    "one_user = [0]\n",
    "all_recall_list = list(map(lambda x: evaluate_topk_recall(testdata=binary_test_user_item_interaction_data, \n",
    "                                                          one_user=x,\n",
    "                                                          user_column=\"user_id\",\n",
    "                                                          item_column=\"movie_id\",\n",
    "                                                          true_result_column=\"value\"), binary_test_user_id))\n",
    "\n",
    "# 6. 將所有Recall平均\n",
    "final_recall = np.array(all_recall_list).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_features = 10\n",
    "\n",
    "# 1. 把所有東西包成dataloader\n",
    "train_dataset = TensorDataset( torch.FloatTensor(rating_train_user_age_onehotencoding),\n",
    "                               torch.FloatTensor(rating_train_user_occupation_onehotencoding),\n",
    "                               torch.FloatTensor(rating_train_movie_feature_data.values),\n",
    "                               torch.FloatTensor(rating_train_result_data) )\n",
    "test_dataset = TensorDataset(  torch.FloatTensor(rating_test_user_age_onehotencoding),\n",
    "                               torch.FloatTensor(rating_test_user_occupation_onehotencoding),\n",
    "                               torch.FloatTensor(rating_test_movie_feature_data.values),\n",
    "                               torch.FloatTensor(rating_test_result_data))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128)\n",
    "\n",
    "\n",
    "\n",
    "# 2. 呼叫模型與設定Loss function\n",
    "model = ipnn_model(num_user_age=rating_train_user_age_onehotencoding.shape[1], \n",
    "                 num_user_occupation=rating_train_user_occupation_onehotencoding.shape[1], \n",
    "                 num_movie_genre=rating_train_movie_feature_data.values.shape[1],\n",
    "                 num_features=num_features)\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch: 0, Train Loss: 2003.3519181013107\n",
      "=== Epoch: 1, Train Loss: 793.9028970599174\n",
      "=== Epoch: 2, Train Loss: 793.8328919410706\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "train_each_iteration_loss = list()\n",
    "train_loss_list = list()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    for torch_user_age, torch_user_occupation, torch_movie_genre, torch_result in train_dataloader:\n",
    "        yhat = model(user_age_feature=torch_user_age, \n",
    "                     user_occupation_feature=torch_user_occupation,\n",
    "                     movie_genre_feature=torch_movie_genre)\n",
    "\n",
    "        loss = loss_func(yhat, torch_result)\n",
    "        train_loss += loss.item()\n",
    "        train_each_iteration_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    train_loss_list.append(train_loss)\n",
    "    print(f\"=== Epoch: {epoch}, Train Loss: {train_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GDBT+LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_features = 10\n",
    "\n",
    "# 1. 把所有東西包成dataloader\n",
    "train_dataset = TensorDataset( torch.FloatTensor(train_user_age_onehotencoding),\n",
    "                               torch.FloatTensor(train_user_occupation_onehotencoding),\n",
    "                               torch.FloatTensor(train_movie_feature_data.values),\n",
    "                               torch.FloatTensor(train_result_data) )\n",
    "test_dataset = TensorDataset(  torch.FloatTensor(test_user_age_onehotencoding),\n",
    "                               torch.FloatTensor(test_user_occupation_onehotencoding),\n",
    "                               torch.FloatTensor(test_movie_feature_data.values),\n",
    "                               torch.FloatTensor(test_result_data))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128)\n",
    "\n",
    "\n",
    "# 2. 呼叫模型與設定Loss function\n",
    "model = fnn_model(num_user_age=train_user_age_onehotencoding.shape[1], \n",
    "                 num_user_occupation=train_user_occupation_onehotencoding.shape[1], \n",
    "                 num_movie_genre=train_movie_feature_data.values.shape[1],\n",
    "                 num_features=num_features)\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch: 0, Train Loss: 1832.3123235106468\n",
      "=== Epoch: 1, Train Loss: 745.8843268752098\n",
      "=== Epoch: 2, Train Loss: 745.6503906846046\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "train_each_iteration_loss = list()\n",
    "train_loss_list = list()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    for torch_user_age, torch_user_occupation, torch_movie_genre, torch_result in train_dataloader:\n",
    "        yhat = model(user_age_feature=torch_user_age, \n",
    "                     user_occupation_feature=torch_user_occupation,\n",
    "                     movie_genre_feature=torch_movie_genre)\n",
    "\n",
    "        loss = loss_func(yhat, torch_result)\n",
    "        train_loss += loss.item()\n",
    "        train_each_iteration_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    train_loss_list.append(train_loss)\n",
    "    print(f\"=== Epoch: {epoch}, Train Loss: {train_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_features = 10\n",
    "\n",
    "# 1. 把所有東西包成dataloader\n",
    "train_dataset = TensorDataset( torch.FloatTensor(train_user_age_onehotencoding),\n",
    "                               torch.FloatTensor(train_user_occupation_onehotencoding),\n",
    "                               torch.FloatTensor(train_movie_feature_data.values),\n",
    "                               torch.FloatTensor(train_result_data) )\n",
    "test_dataset = TensorDataset(  torch.FloatTensor(test_user_age_onehotencoding),\n",
    "                               torch.FloatTensor(test_user_occupation_onehotencoding),\n",
    "                               torch.FloatTensor(test_movie_feature_data.values),\n",
    "                               torch.FloatTensor(test_result_data))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128)\n",
    "\n",
    "\n",
    "# 2. 呼叫模型與設定Loss function\n",
    "model = opnn_model(num_user_age=train_user_age_onehotencoding.shape[1], \n",
    "                 num_user_occupation=train_user_occupation_onehotencoding.shape[1], \n",
    "                 num_movie_genre=train_movie_feature_data.values.shape[1],\n",
    "                 num_decoder=3*(num_features**2)+3,\n",
    "                 num_features=num_features)\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch: 0, Train Loss: 816.1337397694588\n",
      "=== Epoch: 1, Train Loss: 744.1182813048363\n",
      "=== Epoch: 2, Train Loss: 743.7272185087204\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "train_each_iteration_loss = list()\n",
    "train_loss_list = list()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    for torch_user_age, torch_user_occupation, torch_movie_genre, torch_result in train_dataloader:\n",
    "        yhat = model(user_age_feature=torch_user_age, \n",
    "                     user_occupation_feature=torch_user_occupation,\n",
    "                     movie_genre_feature=torch_movie_genre)\n",
    "\n",
    "        loss = loss_func(yhat, torch_result)\n",
    "        train_loss += loss.item()\n",
    "        train_each_iteration_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    train_loss_list.append(train_loss)\n",
    "    print(f\"=== Epoch: {epoch}, Train Loss: {train_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_features = 10\n",
    "\n",
    "# 1. 把所有東西包成dataloader\n",
    "train_dataset = TensorDataset( torch.FloatTensor(train_user_age_onehotencoding),\n",
    "                               torch.FloatTensor(train_user_occupation_onehotencoding),\n",
    "                               torch.FloatTensor(train_movie_feature_data.values),\n",
    "                               torch.FloatTensor(train_result_data) )\n",
    "test_dataset = TensorDataset(  torch.FloatTensor(test_user_age_onehotencoding),\n",
    "                               torch.FloatTensor(test_user_occupation_onehotencoding),\n",
    "                               torch.FloatTensor(test_movie_feature_data.values),\n",
    "                               torch.FloatTensor(test_result_data))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128)\n",
    "\n",
    "\n",
    "# 2. 呼叫模型與設定Loss function\n",
    "model = pin_model(num_user_age=train_user_age_onehotencoding.shape[1], \n",
    "                 num_user_occupation=train_user_occupation_onehotencoding.shape[1], \n",
    "                 num_movie_genre=train_movie_feature_data.values.shape[1],\n",
    "                 num_decoder=3 * num_features,\n",
    "                 num_features=num_features)\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([120, 8])\n",
      "=== Epoch: 0, Train Loss: 743.3026048541069\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([120, 8])\n",
      "=== Epoch: 1, Train Loss: 743.2963911294937\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([128, 8])\n",
      "torch.Size([120, 8])\n",
      "=== Epoch: 2, Train Loss: 743.2903951406479\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "train_each_iteration_loss = list()\n",
    "train_loss_list = list()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    for torch_user_age, torch_user_occupation, torch_movie_genre, torch_result in train_dataloader:\n",
    "        print(torch_user_age.size())\n",
    "        yhat = model(user_age_feature=torch_user_age, \n",
    "                     user_occupation_feature=torch_user_occupation,\n",
    "                     movie_genre_feature=torch_movie_genre)\n",
    "\n",
    "        loss = loss_func(yhat, torch_result)\n",
    "        train_loss += loss.item()\n",
    "        train_each_iteration_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    train_loss_list.append(train_loss)\n",
    "    print(f\"=== Epoch: {epoch}, Train Loss: {train_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_features = 10\n",
    "\n",
    "# 1. 把所有東西包成dataloader\n",
    "train_dataset = TensorDataset( torch.FloatTensor(train_user_age_onehotencoding),\n",
    "                               torch.FloatTensor(train_user_occupation_onehotencoding),\n",
    "                               torch.FloatTensor(train_movie_feature_data.values),\n",
    "                               torch.FloatTensor(train_result_data) )\n",
    "test_dataset = TensorDataset(  torch.FloatTensor(test_user_age_onehotencoding),\n",
    "                               torch.FloatTensor(test_user_occupation_onehotencoding),\n",
    "                               torch.FloatTensor(test_movie_feature_data.values),\n",
    "                               torch.FloatTensor(test_result_data))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128)\n",
    "\n",
    "\n",
    "# 2. 呼叫模型與設定Loss function\n",
    "model = pin_model(num_user_age=train_user_age_onehotencoding.shape[1], \n",
    "                 num_user_occupation=train_user_occupation_onehotencoding.shape[1], \n",
    "                 num_movie_genre=train_movie_feature_data.values.shape[1],\n",
    "                 num_decoder=3 * num_features,\n",
    "                 num_features=num_features)\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch: 0, Train Loss: 743.2036992311478\n",
      "=== Epoch: 1, Train Loss: 743.2006698846817\n",
      "=== Epoch: 2, Train Loss: 743.1977047920227\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "train_each_iteration_loss = list()\n",
    "train_loss_list = list()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    for torch_user_age, torch_user_occupation, torch_movie_genre, torch_result in train_dataloader:\n",
    "        yhat = model(user_age_feature=torch_user_age, \n",
    "                     user_occupation_feature=torch_user_occupation,\n",
    "                     movie_genre_feature=torch_movie_genre)\n",
    "\n",
    "        loss = loss_func(yhat, torch_result)\n",
    "        train_loss += loss.item()\n",
    "        train_each_iteration_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    train_loss_list.append(train_loss)\n",
    "    print(f\"=== Epoch: {epoch}, Train Loss: {train_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMF in NeuCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_features = 20\n",
    "\n",
    "train_dataset = TensorDataset( torch.FloatTensor(rating_train_user_id_onehotencoding),\n",
    "                               torch.FloatTensor(rating_train_movie_id_onehotencoding),\n",
    "                               torch.FloatTensor(rating_train_result_data) )\n",
    "test_dataset = TensorDataset( torch.FloatTensor(rating_test_user_id_onehotencoding),\n",
    "                              torch.FloatTensor(rating_test_movie_id_onehotencoding),\n",
    "                              torch.FloatTensor(rating_test_result_data))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "model = gmf_neucf_model( num_user=rating_train_user_id_onehotencoding.shape[1],\n",
    "                         num_item=rating_train_movie_id_onehotencoding.shape[1],\n",
    "                         num_features=num_features)\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch: 0, Train Loss: 3663.477033853531\n",
      "=== Epoch: 1, Train Loss: 1028.2818360328674\n",
      "=== Epoch: 2, Train Loss: 812.5593981742859\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "train_each_iteration_loss = list()\n",
    "train_loss_list = list()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    for torch_user, torch_movie, torch_result in train_dataloader:\n",
    "        yhat = model(user=torch_user,\n",
    "                     item=torch_movie)\n",
    "\n",
    "        loss = loss_func(yhat, torch_result)\n",
    "        train_loss += loss.item()\n",
    "        train_each_iteration_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    train_loss_list.append(train_loss)\n",
    "    print(f\"=== Epoch: {epoch}, Train Loss: {train_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP in NeuCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_features = 20\n",
    "\n",
    "train_dataset = TensorDataset( torch.FloatTensor(rating_train_user_id_onehotencoding),\n",
    "                               torch.FloatTensor(rating_train_movie_id_onehotencoding),\n",
    "                               torch.FloatTensor(rating_train_result_data) )\n",
    "test_dataset = TensorDataset( torch.FloatTensor(rating_test_user_id_onehotencoding),\n",
    "                              torch.FloatTensor(rating_test_movie_id_onehotencoding),\n",
    "                              torch.FloatTensor(rating_test_result_data))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "model = mlp_neucf_model( num_user=rating_train_user_id_onehotencoding.shape[1],\n",
    "                         num_item=rating_train_movie_id_onehotencoding.shape[1],\n",
    "                         num_features=num_features)\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch: 0, Train Loss: 2382.4753637313843\n",
      "=== Epoch: 1, Train Loss: 793.3175737261772\n",
      "=== Epoch: 2, Train Loss: 793.259542286396\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "train_each_iteration_loss = list()\n",
    "train_loss_list = list()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    for torch_user, torch_movie, torch_result in train_dataloader:\n",
    "        yhat = model(user=torch_user,\n",
    "                     item=torch_movie)\n",
    "\n",
    "        loss = loss_func(yhat, torch_result)\n",
    "        train_loss += loss.item()\n",
    "        train_each_iteration_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    train_loss_list.append(train_loss)\n",
    "    print(f\"=== Epoch: {epoch}, Train Loss: {train_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f5cf5fa73e76fbdd1036fecfade4ba56213682791ca6f80f15a6630a2bc06098"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
